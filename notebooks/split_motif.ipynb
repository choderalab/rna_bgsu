{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df0c10b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, shutil\n",
    "import pathlib\n",
    "import glob as glob\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "from pdbfixer import PDBFixer\n",
    "from openmm.app import PDBxFile, PDBFile\n",
    "from openmm.unit import *\n",
    "import mdtraj as md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05a68de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ebe9a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dir(output_path):\n",
    "    \"\"\"\n",
    "    Create output directory\n",
    "    \"\"\"\n",
    "    if os.path.isdir(output_path):\n",
    "        print(\">remove directory\")\n",
    "        shutil.rmtree(output_path)\n",
    "    \n",
    "    pathlib.Path(output_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24e10937",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_file(files):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    curated_files = []\n",
    "    \n",
    "    for file in files:\n",
    "        basename = os.path.basename(file)\n",
    "\n",
    "        with warnings.catch_warnings(record=True) as w:\n",
    "            warnings.simplefilter(\"default\")\n",
    "            fixer = PDBFixer(filename=file)\n",
    "\n",
    "        fixer.findMissingResidues()\n",
    "        fixer.findMissingAtoms()\n",
    "        if fixer.missingAtoms:\n",
    "            print(\"{}: Missing atoms\".format(basename))\n",
    "\n",
    "        n_atoms = 0\n",
    "        n_residues = 0\n",
    "        with open(file, \"r\") as rf:\n",
    "            for l in rf.readlines():\n",
    "                _l = l.strip('\\n').split()\n",
    "                if l.startswith(\"ATOM\"):\n",
    "                    n_atoms += 1\n",
    "                    symbol = _l[2]\n",
    "                    if symbol == \"P\":\n",
    "                        n_residues += 1\n",
    "\n",
    "\n",
    "        if fixer.topology.getNumAtoms() != n_atoms:\n",
    "            print(\"{}: number of atoms does not match (residues: {}->{} / atoms: {}->{})\".format(basename, \\\n",
    "                                                                                                 n_residues, fixer.topology.getNumResidues(), \\\n",
    "                                                                                                 n_atoms, fixer.topology.getNumAtoms()))\n",
    "            # export pdb\n",
    "            shutil.move(file, file + \".warning\")\n",
    "        else:\n",
    "            curated_files.append(file)\n",
    "\n",
    "    return curated_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dbdc223",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_file(output_path, file):\n",
    "    basename_noext = os.path.basename(file).split('.cif')[0]\n",
    "    #print(basename_noext)\n",
    "    \n",
    "    dumpfile = os.path.join(output_path, \"dump\", basename_noext + \".pdb\")\n",
    "\n",
    "    # load cif, check connectivity, and split structures\n",
    "    fixer = PDBFixer(filename=file)\n",
    "    \n",
    "    PDBFile.writeFile(fixer.topology, fixer.positions, open(dumpfile, 'w'))       # save cif as pdb (dump)\n",
    "    residues = [ residue for residue in fixer.topology.residues() ]\n",
    "    \n",
    "    for i in range(1, len(residues)-1):\n",
    "        \"\"\"\n",
    "        Examples\n",
    "        ---------\n",
    "        [Bond(<Atom 8 (O3') of chain 0 residue 0 (U)>, <Atom 20 (P) of chain 0 residue 1 (G)>)]\n",
    "        [Bond(<Atom 8 (O3') of chain 0 residue 0 (U)>, <Atom 20 (P) of chain 0 residue 1 (G)>), Bond(<Atom 28 (O3') of chain 0 residue 1 (G)>, <Atom 43 (P) of chain 0 residue 2 (C)>)]\n",
    "        [Bond(<Atom 28 (O3') of chain 0 residue 1 (G)>, <Atom 43 (P) of chain 0 residue 2 (C)>), Bond(<Atom 51 (O3') of chain 0 residue 2 (C)>, <Atom 63 (P) of chain 0 residue 3 (A)>)]\n",
    "        [Bond(<Atom 51 (O3') of chain 0 residue 2 (C)>, <Atom 63 (P) of chain 0 residue 3 (A)>), Bond(<Atom 71 (O3') of chain 0 residue 3 (A)>, <Atom 85 (P) of chain 0 residue 4 (A)>)]\n",
    "        [Bond(<Atom 71 (O3') of chain 0 residue 3 (A)>, <Atom 85 (P) of chain 0 residue 4 (A)>), Bond(<Atom 93 (O3') of chain 0 residue 4 (A)>, <Atom 107 (P) of chain 0 residue 5 (C)>)]\n",
    "        [Bond(<Atom 93 (O3') of chain 0 residue 4 (A)>, <Atom 107 (P) of chain 0 residue 5 (C)>)]\n",
    "        \"\"\"\n",
    "\n",
    "        b = [ r for r in residues[i].external_bonds() ]\n",
    "\n",
    "        try:\n",
    "            #b2 = [ r for r in residues[i].external_bonds() ][1]\n",
    "        \n",
    "            dist1 = calc_dist(fixer, b[0])\n",
    "            dist2 = calc_dist(fixer, b[1])\n",
    "\n",
    "            if dist1 < 2 and dist2 < 2:\n",
    "                #print(\"{}{}-{}{}-{}{} are connected\".format(b[0].atom1.residue.id, b[0].atom1.residue.name, \\\n",
    "                #                                            b[1].atom1.residue.id, b[1].atom1.residue.name, \\\n",
    "                #                                            b[1].atom2.residue.id, b[1].atom2.residue.name))\n",
    "\n",
    "                indices = []\n",
    "                indices = [ atom.index for atom in b[0].atom1.residue.atoms() if atom.name not in [\"P\", \"OP1\", \"OP2\"] and atom.element.symbol != \"H\" ]   # exclude P, OP1, and OP2 to handle as 5' base residue\n",
    "                indices += [ atom.index for atom in b[1].atom1.residue.atoms() if atom.element.symbol != \"H\" ]\n",
    "                indices += [ atom.index for atom in b[1].atom2.residue.atoms() if atom.element.symbol != \"H\" ]\n",
    "\n",
    "                rna_seq = b[0].atom1.residue.name + b[1].atom1.residue.name + b[1].atom2.residue.name\n",
    "                outfile = basename_noext + \"_\" + rna_seq + \"_\" + str(i) + \".pdb\"\n",
    "\n",
    "                traj = md.load_pdb(dumpfile, atom_indices=indices)\n",
    "                traj.save_pdb(os.path.join(output_path, \"triplebase\", outfile))\n",
    "        except:\n",
    "            if len(b) == 0:\n",
    "                warnings.warn(\"Warning: no connectivity found ({})\".format(file))\n",
    "                warnings.warn(\"{}\".format(b))\n",
    "            elif len(b) == 1:\n",
    "                pass\n",
    "            else:\n",
    "                warnings.warn(\"Warning: two connectivity found but could not process ({})\".format(file))\n",
    "                warnings.warn(\"{}\".format(b))\n",
    "            \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ffa7b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dist(fixer, b):\n",
    "    x = fixer.positions[b.atom1.index] - fixer.positions[b.atom2.index]\n",
    "    d = sum([ v**2 for v in x.value_in_unit(angstroms) ])\n",
    "    \n",
    "    return sqrt(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b39444c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    base_path = os.path.dirname(os.path.abspath(\"__file__\")).strip('notebooks')    \n",
    "    release_versions = [ \"HairpinLoopMotifAtlasRelease3.57\", \"InternalLoopMotifAtlasRelease3.57\", \"nrlist_3.233_2.5A/JunctionLoop\" ]\n",
    "    \n",
    "    \n",
    "    # create directory\n",
    "    for release_version in release_versions:\n",
    "        output_path = os.path.join(base_path, \"pdb\", \"motif\", release_version)\n",
    "        \n",
    "        make_dir(output_path)\n",
    "        make_dir(os.path.join(output_path, \"dump\"))\n",
    "        make_dir(os.path.join(output_path, \"triplebase\"))\n",
    "        \n",
    "        files = glob.glob(os.path.join(base_path) + \"data/{}/*.cif\".format(release_version))\n",
    "        curated_files = check_file(files)    \n",
    "        \n",
    "        for file in curated_files:\n",
    "            export_file(output_path, file)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e3ebcb",
   "metadata": {},
   "source": [
    "### check warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44743757",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = \"/Users/takabak/work/rna_bgsu/data/HairpinLoopMotifAtlasRelease3.57/HL_01181.4.cif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d406e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixer = PDBFixer(filename=f)\n",
    "residues = [ residue for residue in fixer.topology.residues() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d34b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(residues)-1):\n",
    "    b = [ r for r in residues[i].external_bonds() ]\n",
    "    print(i, len(b), b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfae5bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "residues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31723a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
